{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 91.,  87.,  65.],\n",
      "        [101.,  44.,  37.],\n",
      "        [ 68.,  97.,  70.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 88., 134.,  59.]])\n",
      "tensor([[ 80., 102.],\n",
      "        [ 21.,  38.],\n",
      "        [102., 120.],\n",
      "        [ 81., 101.],\n",
      "        [118., 132.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3710,  0.3287, -0.4189],\n",
      "        [ 0.3472,  0.3483,  0.4933]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1720, -0.1227], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Defining a Model\n",
    "model = nn.Linear(3, 2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 31.2649,  69.7740],\n",
      "        [ 36.0487,  93.6984],\n",
      "        [ 52.1989, 105.3706],\n",
      "        [ 36.6476,  68.5248],\n",
      "        [ 28.0035,  91.8057],\n",
      "        [ 31.3071,  69.7730],\n",
      "        [ 35.3011,  93.8435],\n",
      "        [ 52.1510, 106.2111],\n",
      "        [ 36.6053,  68.5258],\n",
      "        [ 27.2136,  91.9518],\n",
      "        [ 30.5173,  69.9191],\n",
      "        [ 36.0910,  93.6974],\n",
      "        [ 52.9465, 105.2255],\n",
      "        [ 37.4374,  68.3787],\n",
      "        [ 27.9612,  91.8068]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "predict = model(inputs)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
      "\n",
      "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "\n",
      "Args:\n",
      "    in_features: size of each input sample\n",
      "    out_features: size of each output sample\n",
      "    bias: If set to ``False``, the layer will not learn an additive bias.\n",
      "        Default: ``True``\n",
      "\n",
      "Shape:\n",
      "    - Input: :math:`(N, *, H_{in})` where :math:`*` means any number of\n",
      "      additional dimensions and :math:`H_{in} = \\text{in\\_features}`\n",
      "    - Output: :math:`(N, *, H_{out})` where all but the last dimension\n",
      "      are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
      "\n",
      "Attributes:\n",
      "    weight: the learnable weights of the module of shape\n",
      "        :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
      "        initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "        :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "    bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      "            If :attr:`bias` is ``True``, the values are initialized from\n",
      "            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> m = nn.Linear(20, 30)\n",
      "    >>> input = torch.randn(128, 20)\n",
      "    >>> output = m(input)\n",
      "    >>> print(output.size())\n",
      "    torch.Size([128, 30])\n",
      "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     _LinearWithBias, Linear\n"
     ]
    }
   ],
   "source": [
    "?nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1545.7784, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Loss Function\n",
    "loss = F.mse_loss(predict, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer\n",
    "\n",
    "Instead of manually manipulating the model's weights & biases using gradients, we can use the optimizer optim.SGD. SGD is short for \"stochastic gradient descent\". The term stochastic indicates that samples are selected in random batches instead of as a single group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `model.parameters()` is passed as an argument to `optim.SGD` so that the optimizer knows which matrices should be modified during the update step. Also, we can specify a learning rate that controls the amount by which the parameters are modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(no_epoch, model, loss_fn, opt):\n",
    "    for epoch in range(no_epoch):\n",
    "        for xb, yb in train_dl:\n",
    "            predict = model(xb)\n",
    "            loss = loss_fn(predict, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            # Print the progress\n",
    "            if (epoch+1) % 10 == 0:\n",
    "                print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, no_epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 513.6397\n",
      "Epoch [10/100], Loss: 605.7823\n",
      "Epoch [10/100], Loss: 165.7368\n",
      "Epoch [20/100], Loss: 387.4932\n",
      "Epoch [20/100], Loss: 287.4246\n",
      "Epoch [20/100], Loss: 232.1525\n",
      "Epoch [30/100], Loss: 160.4231\n",
      "Epoch [30/100], Loss: 146.5717\n",
      "Epoch [30/100], Loss: 356.8982\n",
      "Epoch [40/100], Loss: 207.7266\n",
      "Epoch [40/100], Loss: 168.4710\n",
      "Epoch [40/100], Loss: 106.9063\n",
      "Epoch [50/100], Loss: 97.5026\n",
      "Epoch [50/100], Loss: 185.7493\n",
      "Epoch [50/100], Loss: 85.8614\n",
      "Epoch [60/100], Loss: 47.8863\n",
      "Epoch [60/100], Loss: 136.1805\n",
      "Epoch [60/100], Loss: 95.5895\n",
      "Epoch [70/100], Loss: 68.5815\n",
      "Epoch [70/100], Loss: 74.1518\n",
      "Epoch [70/100], Loss: 76.1277\n",
      "Epoch [80/100], Loss: 57.8781\n",
      "Epoch [80/100], Loss: 57.2032\n",
      "Epoch [80/100], Loss: 70.1635\n",
      "Epoch [90/100], Loss: 36.0238\n",
      "Epoch [90/100], Loss: 45.3950\n",
      "Epoch [90/100], Loss: 72.8807\n",
      "Epoch [100/100], Loss: 37.5444\n",
      "Epoch [100/100], Loss: 82.1230\n",
      "Epoch [100/100], Loss: 14.4629\n"
     ]
    }
   ],
   "source": [
    "fit(100,model,F.mse_loss, opt)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
